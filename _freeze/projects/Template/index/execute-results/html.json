{
  "hash": "39bca1f5ca4ee6072453abb39c4ee0cf",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: '2024-03-08'\ntitle: \"Example Paper\"\ncategories: [Paper, Python, Dataviz]\nimage: /assets/iris_pca.png\ntitle-block-banner: false\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-tools: true\n    link-external-icon: true\n    link-external-newwindow: true\n---\n\n::: {#f9463d5f .cell execution_count=1}\n``` {.python .cell-code}\nimport io\nfrom sklearn import get_config\nfrom config import save_system\nfrom encryption import RandomState\nimport tomli\nfrom contextlib import redirect_stdout\n\n# remove stupid advert\nf = io.StringIO()\nwith redirect_stdout(f):\n  import ydata_profiling as yd\n\nfrom pycaret.datasets import get_data\nfrom pycaret.classification.functional import setup, get_config, compare_models, create_model, pull, finalize_model, save_model, plot_model, evaluate_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'DeJavu Serif'\nplt.rcParams['font.serif'] = ['Times New Roman']\nfrom yellowbrick.features import rank2d\nimport yellowbrick as yb\nimport dtreeviz\n```\n:::\n\n\n::: {#f74d98a5 .cell execution_count=2}\n``` {.python .cell-code}\nsave_system()\n\nwith open(\"../../pyproject.toml\", mode=\"rb\") as fp:\n  config = tomli.load(fp)\n\nPROJECT_NAME = config[\"tool\"][\"poetry\"][\"name\"]\nRANDOM_STATE = RandomState(PROJECT_NAME).state\n```\n:::\n\n\n# Classifying Irises by Field Measurements\n\n*Classification is a machine learning technique used to predict group membership for data instances.\nThe problem concerns the identification of IRIS plant species on the\nbasis of plant attribute measurements. Classification of IRIS data set would be discovering patterns\nfrom examining petal and sepal size of the IRIS plant and how the prediction was made from analyzing the\npattern to form the class of IRIS plant. By using this pattern and classification, it is possible to\naccurately predict the IRIS Species. Support Vector Machines (SVM) have been\ndeployed to perform classification of datasets efficiently. In this work, dimensionality\nreduction techniques such as PCA will be used in conjunction with SVM to classify.*\n\n## Introduction\n\nBio-informatics is a promising and novel research area in the 21st century. This field is data\ndriven and aims at understanding of relationships and gaining knowledge in biology. In order to\nextract this knowledge encoded in biological data, advanced computational technologies,\nalgorithms and tools need to be used. Basic problems in bio-informatics like protein structure\nprediction, multiple alignments of sequences, phylogenic inferences, etc are inherently nondeterministic polynomial-time hard in nature. To solve these kinds of problems artificial\nintelligence (AI) methods offer a powerful and efficient approach. Researchers have used AI\ntechniques like Artificial Neural Networks (ANN), Fuzzy Logic, Genetic Algorithms, and\nSupport Vector Machines to solve problems in bio-informatics.\n\nThe concern of this study is towards the identification of IRIS plants on the basis of the\nfollowing measurements: sepal length, sepal width, petal length, and petal width.\nThis paper is mainly concerned with an analysis of the performance results of classification techniques\nsuch as Decision Tree, Support Vector Machine (SVM) in determining the species of the Iris plants.\n\n## Data\n\nOne of the most popular and best known databases of the neural network application is the IRIS\nplant data set which is obtained from UCI Machine Learning Repository and created by R.A.\nFisher while donated by Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov) on July, 1988\n\nThe IRIS dataset classifies three different classes of IRIS plant by performing pattern\nclassification. The IRIS data set includes three classes of 50 objects each, where each class\nrefers to a type of IRIS plant. The attributed that already been predicted belongs to the class of\nIRIS plant. The list of attributes present in the IRIS can be described as categorical, nominal and\ncontinuous. The experts have mentioned that there isnâ€™t any missing value found in any attribute\nof this data set. The data set is complete.\n\nThis project makes use of the well known IRIS dataset, which refers to three classes of 50\ninstances each, where each class refers to a type of IRIS plant. The first of the classes is linearly\ndistinguishable from the remaining two, with the second two not being linearly separable from\neach other. The 150 instances, which are equally separated between the three classes, contain the\nfollowing four numeric attributes:\n\n::: {#af6e2b60 .cell tbl-cap='Iris Measures' execution_count=3}\n``` {.python .cell-code}\ndata = get_data(\"iris\")\ndecoder = ['setosa', 'versicolor', 'virginica']\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe fifth attribute is the predictive attributes which is the class attribute that means each instance\nalso includes an identifying class name, each of which is one of the following: IRIS Setosa, IRIS\nVersicolour, or IRIS Virginica. A copy of the report can be found here [EDA Report](../../assets/Iris_EDA.html)\n\n::: {#63a1e9e7 .cell execution_count=4}\n``` {.python .cell-code}\nreport = data.profile_report(progress_bar=False, title=\"Iris EDA Report\")\nreport.to_file(\"../../assets/Iris_EDA.html\", silent = True)\n```\n:::\n\n\n## Methods\n\nDimensionality reduction is a really important concept in Machine Learning since\nit reduces the number of features in a dataset and hence reduces the\ncomputations needed to fit the model. **PCA** is one of the well known efficient\ndimensionality reduction techniques. in this tutorial we will use PCA which\ncompresses the data by projecting it to a new subspace that can help in reducing\nthe effect of the **curse of dimensionality**. Our dataset consists of\n4 dimensions(4 features) so we will project it to a 2 dimensions space and\nplot it for visualization.\n\n::: {#e9ae3d63 .cell execution_count=5}\n``` {.python .cell-code}\nenv_pca = setup(data, target=\"species\", train_size = .8, session_id = RANDOM_STATE, pca=True, pca_components = 2, verbose = False, normalize = True)\n```\n:::\n\n\n::: {#c6fc660f .cell tbl-cap='Reduced Dimension Measurements' execution_count=6}\n``` {.python .cell-code}\nenv_pca.X_transformed.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pca0</th>\n      <th>pca1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83</th>\n      <td>-1.069254</td>\n      <td>-0.680773</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2.308932</td>\n      <td>1.167804</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>-0.230247</td>\n      <td>-0.329121</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>-1.329566</td>\n      <td>0.578077</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>0.044678</td>\n      <td>-1.574244</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe first principle component has the highest explained variance, followed by the 2nd component. By plotting these 2 components, we get a view of the 4 dimensions with as much explained variance as possible for a linear transformation. Although not a guarantee to be beneficial, often as in this case, clear separation of the target class can be observed in the transformed subspace.\n\n::: {#995d98d1 .cell execution_count=7}\n``` {.python .cell-code}\npca = env_pca.pipeline.named_steps[\"pca\"].transformer\nplt.figure()\nsns.scatterplot(env_pca.X_transformed, x=\"pca0\", y=\"pca1\", hue=data[\"species\"]).set(title=\"IRIS Species Scatter Plot \\n Explained Variance: %.3f\" % pca.explained_variance_ratio_.sum())\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\n### Feature Importance\nWhile PCA is great for dimensionality reduction and visualization, we do lose some interpretability in how the scientific measurements are correlated to the target species. For this, we look at feature rank and feature importance charts to determine the measurements most affecting the separation between classes.\n\n::: {#acc73886 .cell execution_count=8}\n``` {.python .cell-code}\nenv_norm = setup(data, target=\"species\", train_size = .8, session_id = RANDOM_STATE, verbose = False, normalize=True)\n```\n:::\n\n\n::: {#a585eabd .cell layout-ncol='2' execution_count=9}\n``` {.python .cell-code}\nfig = rank2d(get_config(\"X_train\"), get_config(\"y_train\"))\nfig = yb.target.feature_correlation.feature_correlation(env_norm.X_train, env_norm.y_train, method='mutual_info-classification')\n```\n\n::: {.cell-output .cell-output-display}\n![Pairwise Feature Correlation](index_files/figure-html/cell-10-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![Target Correlation](index_files/figure-html/cell-10-output-2.png){}\n:::\n:::\n\n\n<br>\nStandard practice is to perform train test split on the transformed data to evaluate the model performance.\nWe will use the convention that splits the data in 80% training/validation and 20% test set.\nBecause the sample size is relatively small, we will use cross validation to prevent overfitting.\nWe set the random state to a constant value in order to get consistent results when we rerun the code.\nThe advantages of this technique are the ability to limit overfitting on a relatively small dataset.\n\n::: {#55ab71b2 .cell execution_count=10}\n``` {.python .cell-code}\nfig = yb.target.class_balance(env_norm.y_train, env_norm.y_test, labels = decoder)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){}\n:::\n:::\n\n\n## Analysis\n\nIn this section, we analyze how our primary models performed,\nand discuss reasons why they did not perform even\nbetter. Specifically, we will analyze why certain species were\ncommonly confused with others. Confusing **versicolor** and **virginica**\nis understandable based on the boundary overlap in the PCA analysis.\n\nThe results of the SVM model on unseen data are measured on the f1 score, a\ngeometric mean of the precision and recall scores. This measure is considered\na more realistic measure of the overall accuracy of the classification model. Of interest is the variation in performance on each cross validation run. A standard deviation in the range of 5%-10% may see performance results on test or production data far inferior than what is reported in validation. \n\n::: {#ba05a318 .cell tbl-cap='Cross Validation Results' execution_count=11}\n``` {.python .cell-code}\n# Modeling\nsvm_model = create_model(\"svm\", tol=1e-3, alpha=.0012, verbose=False) # parameters can be found with tune_model\npull()\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.7500</td>\n      <td>0.0</td>\n      <td>0.7500</td>\n      <td>0.7556</td>\n      <td>0.7460</td>\n      <td>0.6250</td>\n      <td>0.6316</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.9167</td>\n      <td>0.0</td>\n      <td>0.9167</td>\n      <td>0.9333</td>\n      <td>0.9153</td>\n      <td>0.8750</td>\n      <td>0.8843</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.9167</td>\n      <td>0.0</td>\n      <td>0.9167</td>\n      <td>0.9333</td>\n      <td>0.9153</td>\n      <td>0.8750</td>\n      <td>0.8843</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.9167</td>\n      <td>0.0</td>\n      <td>0.9167</td>\n      <td>0.9333</td>\n      <td>0.9153</td>\n      <td>0.8750</td>\n      <td>0.8843</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0000</td>\n      <td>0.0</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.8333</td>\n      <td>0.0</td>\n      <td>0.8333</td>\n      <td>0.8333</td>\n      <td>0.8333</td>\n      <td>0.7500</td>\n      <td>0.7500</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0000</td>\n      <td>0.0</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0000</td>\n      <td>0.0</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.9167</td>\n      <td>0.0</td>\n      <td>0.9167</td>\n      <td>0.9333</td>\n      <td>0.9153</td>\n      <td>0.8750</td>\n      <td>0.8843</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.8333</td>\n      <td>0.0</td>\n      <td>0.8333</td>\n      <td>0.8889</td>\n      <td>0.8222</td>\n      <td>0.7500</td>\n      <td>0.7833</td>\n    </tr>\n    <tr>\n      <th>Mean</th>\n      <td>0.9083</td>\n      <td>0.0</td>\n      <td>0.9083</td>\n      <td>0.9211</td>\n      <td>0.9063</td>\n      <td>0.8625</td>\n      <td>0.8702</td>\n    </tr>\n    <tr>\n      <th>Std</th>\n      <td>0.0786</td>\n      <td>0.0</td>\n      <td>0.0786</td>\n      <td>0.0744</td>\n      <td>0.0805</td>\n      <td>0.1179</td>\n      <td>0.1141</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nFor comparison, a simple decision tree was trained as well. The following metrics demonstrate the varying performance on each class of the models. Standard metrics for classification are precision, recall and f1 score for each class as well as a confusion matrix. A ROC curve would also be included to demonstrate how the model performance can very even within a confusion matrix if you take into account a rank function. Such a rank function is generally only available for models as using probability based classification such as logistic regression.\n\n::: {#7ce5692f .cell execution_count=12}\n``` {.python .cell-code}\ntree_model = create_model(\"dt\", max_depth=3, verbose = False)\nwinning_model = compare_models(include=[svm_model, tree_model], verbose = False)\npull()\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.9500</td>\n      <td>0.9677</td>\n      <td>0.9500</td>\n      <td>0.9600</td>\n      <td>0.9492</td>\n      <td>0.9250</td>\n      <td>0.9306</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.9083</td>\n      <td>0.0000</td>\n      <td>0.9083</td>\n      <td>0.9211</td>\n      <td>0.9063</td>\n      <td>0.8625</td>\n      <td>0.8702</td>\n      <td>0.008</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nMost sources would indicate at this point to choose the best performing model and then run a test on the holdout dataset. It is important to make a model selection before running a holdout test as the performance results of each model may vary on the holdout set and the winning model may change. Because the purpose of the holdout set is to evaluate a model on unseen data, we cannot retroactively choose the best model for said test. \n\nFor demonstration purposes, the performance results for both SVM and Decision Tree on the test set are shown. In the next section, we explain why we may choose a certain model even if inferior in performance.\n\n\n::: {#fig-metrics layout-ncol=2}\n\n::: {#928e3b95 .cell execution_count=13}\n``` {.python .cell-code}\nfig = plot_model(svm_model, plot = \"confusion_matrix\", plot_kwargs = {\"classes\": decoder})\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-2.png){}\n:::\n:::\n\n\n::: {#3763ae0a .cell execution_count=14}\n``` {.python .cell-code}\nfig = plot_model(tree_model, plot = \"confusion_matrix\", plot_kwargs = {\"classes\": decoder})\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){}\n:::\n:::\n\n\n::: {#e193446a .cell execution_count=15}\n``` {.python .cell-code}\nfig = plot_model(svm_model, plot = \"class_report\", plot_kwargs = {\"classes\": decoder})\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-2.png){}\n:::\n:::\n\n\n::: {#52a3c66c .cell execution_count=16}\n``` {.python .cell-code}\nfig = plot_model(tree_model, plot = \"class_report\", plot_kwargs = {\"classes\": decoder})\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-2.png){}\n:::\n:::\n\n\n:::\n\n::: {#2598fb3e .cell execution_count=17}\n``` {.python .cell-code}\nmessage = save_model(svm_model, \"models/svm-model\", verbose = False)\nmessage = save_model(tree_model, \"models/tree-model\", verbose = False)\n```\n:::\n\n\n### Model Interpretability\n\nUnfortunately SVM uses a higher dimensional space to linearly slice the sample space into class specific hyperplanes. Visualizing how this is down is difficult, but understood well geometrically. However, the decision tree can easily be visualized and explain the predictive power of the model on the test set. This example shows a mislabeled iris, but more importantly demonstrates how that incorrect result was obtained. \n\n::: {#0b43680b .cell execution_count=18}\n``` {.python .cell-code}\n# Build a model on the final data for deployment.\nenv_prod = setup(data, target=\"species\", train_size = .8, session_id = RANDOM_STATE, verbose = False) # trees don't need normalization\nfinal_tree = finalize_model(tree_model)\nmessage = save_model(final_tree, \"models/production-model\", verbose = False)\n```\n:::\n\n\n::: {#cf6689e8 .cell execution_count=19}\n``` {.python .cell-code}\n# Visualize predictions\nsample = env_prod.X_transformed.iloc[120] \nfinal_tree_model = final_tree.named_steps['actual_estimator']\nviz_model =  dtreeviz.model(final_tree_model, X_train=env_prod.X_transformed, y_train = env_prod.y_transformed, feature_names = list(env_prod.X_transformed), target_name = \"species name\", class_names = decoder)\nviz_model.view(x = sample, fontname=\"DejaVu Sans\")\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n![](index_files/figure-html/cell-20-output-1.svg){}\n:::\n:::\n\n\nIn-case displaying the entire tree is not desirable especially in regulatory environemts, we can instead display the list of features and their importance related to the decision. \n\n::: {#b4142ca8 .cell execution_count=20}\n``` {.python .cell-code}\nviz_model.instance_feature_importance(sample, fontname=\"DejaVu Sans\")\n#explanation = eli5.explain_prediction(final_tree, env_prod.X.iloc[106], target_names = decoder)\n#print(eli5.format_as_text(explanation), f\"True Class: {decoder[env_prod.y[106]]}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-21-output-1.png){}\n:::\n:::\n\n\n## Conclusion\nWe have constructed a relatively accurate classifier for species of\nIris flowers based on the field measurements. Using PCA analysis to visualize the data\nthere were clear segments that could be made to classify the various species.\nFeeding this data into a Support Vector Machine (SVM), we were able to achieve\na relatively high F1 score with cross validation as well as the test set, thus confirming validation results.\nSimilarly great results were shown for the Decision Tree model as well.\n\nBecause SVM is difficult to perform in the fields, and PCA transforms the data\ninto features that represent eigenvectors, this method will prove difficult to\ninterpret as simple rules of known biological dimensions. For field use, it\nwill be of interest to use other\nclassification methods such as decision tree that is\nboth as accurate if not more soe than SVM and easier to use and understand in the field for biological classification.\n\nOf further interest is the closeness of the **versicolor** and **virginica**\nspecies with regard to the field measurements. Future studies may explore finding another measure to help differentiate them more as we see there is some similarities in their measurements. This would greatly increase the performance of any model for the purpose of classification. \n\n\n## Appendix\n\nThe entire website, including this example project is located at [https://github.com/joshuacharleshyatt/personal](https://github.com/joshuacharleshyatt/personal)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}